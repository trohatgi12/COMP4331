{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2a. (40 points) In this question, you are required to implement (using Keras) a 10-output CNN with the following layers:\n",
    "1. 16 channels of 2 × 2 convolution, with ReLU activation;\n",
    "2. max-pooling layer with stride 2;\n",
    "3. 16 channels of 2 × 2 convolution, with ReLU activation;\n",
    "4. max-pooling layer with stride 2;\n",
    "5. fully connected layer with 120 ReLU hidden units;\n",
    "6. another fully connected layer with 64 ReLU hidden units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we use the MNIST (https://hkustconnect-my.sharepoint.com/:u:/g/personal/ hzhangal_connect_ust_hk/ERzaZJwExepPlf92u_1cCPABLyuC21lBggcZ9GHx0mpyPQ?e=YklceJ) dataset. The first column is the class label. The other columns are the intensity values for each individual pixel in each MNIST image. Each student will have his/her own test set (which is based on your student id). Run your code using adam as the optimizer, train your model for 10 epochs on the training set, and report the accuracy on your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "np.random.seed(0)\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1581, 785)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading data\n",
    "train = np.genfromtxt('asgn2_data/train.csv', delimiter = ',')\n",
    "test = np.genfromtxt('asgn2_data/20380937.csv', delimiter = ',')\n",
    "display(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train[1:,1:].reshape((-1, 28, 28, 1))\n",
    "x_test = test[1:,1:].reshape((-1, 28, 28, 1))\n",
    "y_train = train[1:, 0]\n",
    "y_test = test[1:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "\"\"\"\n",
    "1. 16 channels of 2 × 2 convolution, with ReLU activation; 2. max-pooling layer with stride 2;\n",
    "3. 16 channels of 2 × 2 convolution, with ReLU activation;\n",
    "1\n",
    "4. max-pooling layer with stride 2;\n",
    "5. fully connected layer with 120 ReLU hidden units;\n",
    "6. another fully connected layer with 64 ReLU hidden units\"\"\"\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(2, 2), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    " optimizer=keras.optimizers.Adam(),\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1580 samples, validate on 210 samples\n",
      "Epoch 1/10\n",
      "1580/1580 [==============================] - 1s 588us/step - loss: 2.0321 - accuracy: 0.3994 - val_loss: 1.5831 - val_accuracy: 0.6714\n",
      "Epoch 2/10\n",
      "1580/1580 [==============================] - 0s 272us/step - loss: 1.1609 - accuracy: 0.7291 - val_loss: 0.7597 - val_accuracy: 0.7905\n",
      "Epoch 3/10\n",
      "1580/1580 [==============================] - 0s 291us/step - loss: 0.6039 - accuracy: 0.8228 - val_loss: 0.5039 - val_accuracy: 0.8619\n",
      "Epoch 4/10\n",
      "1580/1580 [==============================] - 0s 279us/step - loss: 0.4219 - accuracy: 0.8772 - val_loss: 0.4423 - val_accuracy: 0.8762\n",
      "Epoch 5/10\n",
      "1580/1580 [==============================] - 0s 285us/step - loss: 0.3257 - accuracy: 0.9038 - val_loss: 0.3181 - val_accuracy: 0.9143\n",
      "Epoch 6/10\n",
      "1580/1580 [==============================] - 1s 352us/step - loss: 0.2637 - accuracy: 0.9259 - val_loss: 0.2813 - val_accuracy: 0.9238\n",
      "Epoch 7/10\n",
      "1580/1580 [==============================] - 0s 273us/step - loss: 0.2224 - accuracy: 0.9361 - val_loss: 0.2579 - val_accuracy: 0.9238\n",
      "Epoch 8/10\n",
      "1580/1580 [==============================] - 0s 285us/step - loss: 0.1874 - accuracy: 0.9494 - val_loss: 0.2659 - val_accuracy: 0.9190\n",
      "Epoch 9/10\n",
      "1580/1580 [==============================] - 0s 280us/step - loss: 0.1713 - accuracy: 0.9525 - val_loss: 0.2240 - val_accuracy: 0.9429\n",
      "Epoch 10/10\n",
      "1580/1580 [==============================] - 0s 281us/step - loss: 0.1397 - accuracy: 0.9652 - val_loss: 0.1883 - val_accuracy: 0.9429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1350e6748>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for the given CNN architecture:  0.9428571462631226\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"accuracy for the given CNN architecture: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Changing parameters for part b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, kernel_size=(4, 4), activation='relu',input_shape=(28, 28, 1))) # unknown model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(16, (4, 4), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='relu')) \n",
    "model.add(Dense(64, activation='relu')) \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=keras.optimizers.Adam(),\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " - 2s - loss: 1.0619 - accuracy: 0.6804\n",
      "Epoch 2/10\n",
      " - 2s - loss: 0.3163 - accuracy: 0.9032\n",
      "Epoch 3/10\n",
      " - 2s - loss: 0.1680 - accuracy: 0.9532\n",
      "Epoch 4/10\n",
      " - 2s - loss: 0.1090 - accuracy: 0.9633\n",
      "Epoch 5/10\n",
      " - 2s - loss: 0.0660 - accuracy: 0.9791\n",
      "Epoch 6/10\n",
      " - 2s - loss: 0.0441 - accuracy: 0.9861\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0301 - accuracy: 0.9943\n",
      "Epoch 8/10\n",
      " - 2s - loss: 0.0242 - accuracy: 0.9930\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0179 - accuracy: 0.9949\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0099 - accuracy: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1360d5f60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10,\n",
    "verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for model with all convolutions of 4x4:  0.9523809552192688\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0) \n",
    "print(\"accuracy for model with all convolutions of 4x4: \", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
